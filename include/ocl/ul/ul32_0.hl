/*
 * AUTOGENERATED tcarstens January 2014
 */
#ifndef __UL32_0__
#define __UL32_0__

#include "../stdint.hl"
#include "../rng.hl"


/*
 * ul32
 */
typedef struct ul32_s {
    uint32_t x[1];
} ul32[1];

inline void ul32_init(ul32 x) { return; }
inline void ul32_clear(ul32 x) { return; }

typedef struct mod32_s {
    ul32 n;
    uint32_t np;
    ul32 rsq;
} mod32[1];




/*
 * Setters
 */
inline void ul32_set_gp(__global ul32 dst, ul32 src) {
    dst->x[0] = src->x[0];
}
inline void ul32_set_pg(ul32 dst, __global ul32 src) {
    dst->x[0] = src->x[0];
}
inline void ul32_set_gg(__global ul32 dst, __global ul32 src) {
    dst->x[0] = src->x[0];
}
inline void ul32_set(ul32 dst, ul32 src) {
    dst->x[0] = src->x[0];
}
/*
 * Set a ul32 to a uint32_t
 */
inline void ul32_set_ui(ul32 dst, uint32_t i) {
    dst->x[0] = i;
}

/*
 * Get a uint32_t out of a ul32
 */
inline uint32_t ul32_get_ui(ul32 src) {
    return src->x[0];
}




/*
 * Generate a random ul32
 */
inline void ul32_rand(struct rng_t *r, ul32 dst) {
    uint64_t w0 = rand_uint64(r);
    
    dst->x[0] = w0 & 0xffffffff;
}



/*
 * Compare two ul32's
 */
inline int ul32_cmp(ul32 src1, ul32 src2) {
    int r = 0;
    if (src1->x[0] > src2->x[0]) r = 1;
    else if (src1->x[0] < src2->x[0]) r = -1;
    return r;
}

/*
 * Compare a ul32 with a uint32_t
 */
inline int ul32_cmp_ui(ul32 src1, uint32_t src2) {
    int r = 0;
    if (src1->x[0] > src2) r = 1;
    else if (src1->x[0] < src2) r = -1;
    return r;
}




/*
 * Add two ul32's
 */
inline void ul32_add(ul32 dst, ul32 src1, ul32 src2) {
    #if defined(UL_NVIDIA)
        asm(
          "add.cc.u32  %0, %1, %2;\n\t"
          "addc.u32    %0, %1, %2;\n\t"
          : "=r" (dst->x[0])
          : "r" (src1->x[0]), 
            "r" (src2->x[0])
          : "cc"
        );
    #else
        ul32 d = { 0 };
        d->x[0] = (src1->x[0] & 0x7fffffff) + (src2->x[0] & 0x7fffffff) + 0;
        uint32_t c0 = (src1->x[0] >> 31) + (src2->x[0] >> 31) + (d->x[0] >> 31);
        d->x[0] = (c0 << 31) | (d->x[0] & 0x7fffffff);
        c0 = c0 >> 1;
        dst->x[0] = d->x[0];
        
    #endif
    return;
}
/*
 * Sub two ul32's
 */
inline void ul32_sub(ul32 dst, ul32 src1, ul32 src2) {
    #if defined(UL_NVIDIA)
        asm(
          "sub.cc.u32  %0, %1, %2;\n\t"
          "subc.u32    %0, %1, %2;\n\t"
          : "=r" (dst->x[0])
          : "r" (src1->x[0]), 
            "r" (src2->x[0])
          : "cc"
        );
    #else
        ul32 d = { 0 };
        d->x[0] = (src1->x[0] & 0x7fffffff) - (src2->x[0] & 0x7fffffff) - 0;
        uint32_t b0 = (src1->x[0] >> 31) - (src2->x[0] >> 31) - (d->x[0] >> 31);
        d->x[0] = (b0 << 31) | (d->x[0] & 0x7fffffff);
        b0 = (b0 >> 1) & 1;
        dst->x[0] = d->x[0];
        
    #endif
    return;
}
/*
 * Mul two ul32's
 */
inline void ul32_mul(ul32 dst, ul32 src1, ul32 src2) {
    #if defined(UL_NVIDIA)
        asm(
          "mul.lo.u32 %0, %1, %2;\n\t"
          : "=r" (dst->x[0])
          : "r" (src1->x[0]), 
            "r" (src2->x[0])
          : "cc"
        );
    #else
        dst->x[0] = src1->x[0] * src2->x[0];
    #endif
    return;
}




/*
 * Initialize mod32
 */
inline void mod32_init(mod32 n) {
}

/*
 * Add two ul32's modulo another
 */
inline void ul32_modadd(ul32 dst, ul32 src1, ul32 src2, mod32 n) {
    ul32_add(dst, src1, src2);
    if (ul32_cmp(dst, n->n) >= 0)
        ul32_sub(dst, dst, n->n);
}

/*
 * Subtract one ul32 from another modulo a third
 */
inline void ul32_modsub(ul32 dst, ul32 src1, ul32 src2, mod32 n) {
    ul32 tr1, tr2;
    ul32_sub(tr1, src1, src2);
    ul32_add(tr2, tr1, n->n);
    if (ul32_cmp(src1, src2) >= 0)
        ul32_set(dst, tr1);
    else
        ul32_set(dst, tr2);
}

/*
 * Mul two ul32's modulo a third, followed by Montgomery reduction
 */
void ul32_modmul(ul32 _dst, ul32 _src1, ul32 _src2, mod32 n) {
    #if defined(UL_NVIDIA)
        volatile ul32 src1;
        volatile ul32 src2;
        /* ul32_set(src1, _src1); */
        src1->x[0] = _src1->x[0];
        /* ul32_set(src2, _src2); */
        src2->x[0] = _src2->x[0];
        
        uint32_t q = 0;
        ul32 dst = { 0 };
        uint32_t dst_1 = 0;
        
        asm(
          /* Compute c_0..0 for the product a*b, with carry-out to dst_1 */
          "mad.lo.cc.u32  %0, %3, %4, %0;\n\t"  /* c_0 += lo(a_0, b_0) */
          "addc.u32 %1, %1, 0;\n\t"  /* accum carry in c_1 */
          
          /* Add in the qN's */
          /* n = 0... */
            /* Compute q = mu * c_0 */
            "mov.u32 %2, %0;\n\t"
            "mul.lo.u32 %2, %2, %6;\n\t"
            /* Update c_0 with qN_0 */
            "mad.lo.cc.u32 %0, %2, %5, %0;\n\t"  /* c_0 += lo(q, n_0) */
            /* Shift */
            "mov.u32 %0, %1;\n\t"  /* dst_0 <- c_1 */
            "xor.b32 %1, %1, %1;\n\t"  /* dst_1 <- c_2 */
            /* Compute and add-in qN, with carry-out to dst_1 */
            "madc.hi.cc.u32 %0, %2, %5, %0;\n\t"  /* c_1 += hi(q, n_0) */
            "addc.u32    %1, %1, 0;\n\t"  /* accum carry in dst_1 */
          
          /* Compute c_1..1 in the product a*b, storing the result in dst_0..0, with carry-out to dst_1 */
          "mad.hi.cc.u32  %0, %3, %4, %0;\n\t"  /* c_1 += hi(a_0, b_0) */
          "addc.u32    %1, %1, 0;\n\t"  /* accum carry in c_2 */
          
          : "+r" (dst->x[0]), "+r" (dst_1), "+r" (q)
          : "r" (src1->x[0]), 
            "r" (src2->x[0]), 
            "r" (n->n->x[0]), 
            "r" (n->np)
        );
        
        /* Reduce as needed */
        if (dst_1 || (ul32_cmp(dst, n->n) >= 0))
            ul32_sub(dst, dst, n->n);
        ul32_set(_dst, dst);
    #else
        /* The pairwise products of the a_i and b_j */
        const uint64_t a_0__b_0 = ((uint64_t)_src1->x[0]) * ((uint64_t)_src2->x[0]);
        const uint32_t a_0__b_0_lo = a_0__b_0;
        const uint32_t a_0__b_0_hi = a_0__b_0 >> 32;
        
        /* Limbs of the product C = A*B */
        uint32_t c_0 = 0;
        uint32_t q_0 = 0;
        uint32_t c_1 = 0;
        uint32_t q_1 = 0;
        uint32_t c_2 = 0;
        uint32_t q_2 = 0;
        
        /* The product of the q_i's with N */
        uint64_t q_0__N_0 = 0;
        
        /* Compute c_0 */
        {
            /* Add the product terms into c_0, accumulating carries in c_1 */
            c_1 += ul32_addc(&c_0, &c_0, &a_0__b_0_lo);
            
            /* Add the q_i*N's for i < 0 */
            
            /* Compute q_0 and add its product with N */
            q_0 = n->np * c_0;
            q_0__N_0 = ((uint64_t)q_0) * ((uint64_t)n->n->x[0]);
            const uint32_t q_0__N_0_lo = q_0__N_0;
            c_1 += ul32_addc(&c_0, &c_0, &q_0__N_0_lo);
        }
        
        /* Compute c_1 */
        {
            /* Add the product terms into c_1, accumulating carries in c_2 */
            c_2 += ul32_addc(&c_1, &c_1, &a_0__b_0_hi);
            
            /* Add the q_i*N's for i < 1 */
            const uint32_t q_0__N_0_hi = q_0__N_0 >> 32;
            c_2 += ul32_addc(&c_1, &c_1, &q_0__N_0_hi);
            
        }
        
        /* R = C * beta^{-n} */
        _dst->x[0] = c_1;
        
        /* Reduce as needed */
        if (c_2 || (ul32_cmp(_dst, n->n) >= 0))
            ul32_sub(_dst, _dst, n->n);
    #endif
}

/*
 * Convert a ul32 into Montgomery form
 */
inline void ul32_to_montgomery(ul32 dst, ul32 src, mod32 mod) {
    ul32_modmul(dst, src, mod->rsq, mod);
}

/*
 * Convert a ul32 out-of Montgomery form
 */
inline void ul32_from_montgomery(ul32 dst, ul32 src, mod32 mod) {
    ul32 one = { 0 };
    one->x[0] = 1;
    
    ul32_modmul(dst, src, one, mod);
}




/*
 * Right-shift a ul32 by some number of bits
 */
inline void ul32_rshift(ul32 dst, ul32 src, int shift) {
dst->x[0] = dst->x[0] >> shift;
}



/*
 * Left shift a ul32 by some number of words
 */
inline void ul32_lshiftw(ul32 dst, ul32 src, int w) {
    dst->x[0] = ((0-w) >= 0) ? src->x[0-w] : 0;
}

/*
 * Multiply a ul32 by a uint32_t
 */
inline void ul32_mulu32(ul32 dst, ul32 src, uint32_t x) {
    uint64_t x_src_0 = ((uint64_t)src->x[0]) * ((uint64_t)x);
    
    dst->x[0] = 0;
    
    dst->x[0] += x_src_0;
}




#endif
